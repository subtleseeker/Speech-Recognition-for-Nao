{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create labels\n",
    "Input: Folder Path   \n",
    "Output: Tuple (Label, Indices of the labels, one-hot encoded labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./eng_data/\"\n",
    "\n",
    "def get_labels(path=DATA_PATH):\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, to_categorical(label_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting wave to mfcc\n",
    "Input: path of file, maximum pad length(default=11)   \n",
    "Output: list of mfcc vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2mfcc(file_path, max_len=11):\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "    wave = wave[::3]\n",
    "    try:\n",
    "        mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
    "    except Exception as e:\n",
    "        print(file_path)\n",
    "        print(e)\n",
    "        \n",
    "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
    "    if (max_len > mfcc.shape[1]):\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    # Else cutoff the remaining parts\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    \n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving mfcc vectors to .npy files\n",
    "Input: path to write files   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_array(path=DATA_PATH, max_len=11):\n",
    "    labels, _, _ = get_labels(path)\n",
    "\n",
    "    for label in labels:\n",
    "        mfcc_vectors = []\n",
    "        wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "        \n",
    "        for wavfile in tqdm(wavfiles, \"Saving vectors of label - '{}'\".format(label)):\n",
    "            mfcc = wav2mfcc(wavfile, max_len=max_len)\n",
    "            mfcc_vectors.append(mfcc)\n",
    "            \n",
    "        np.save(label + '.npy', mfcc_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing data into training set and testing set\n",
    "Input: split ratio (default=0.8)    \n",
    "Output: 2 arrays of training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(split_ratio=0.8):\n",
    "    # Get available labels\n",
    "    labels, indices, _ = get_labels(DATA_PATH)\n",
    "\n",
    "    # Getting first arrays\n",
    "    X = np.load(labels[0] + '.npy')\n",
    "    y = np.zeros(X.shape[0])\n",
    "\n",
    "    # Append all of the dataset into one single array, same goes for y\n",
    "    for i, label in enumerate(labels[1:]):\n",
    "        x = np.load(label + '.npy')\n",
    "        X = np.vstack((X, x))\n",
    "        y = np.append(y, np.full(x.shape[0], fill_value= (i+1)))\n",
    "\n",
    "    assert X.shape[0] == len(y)\n",
    "\n",
    "    return train_test_split(X, y, test_size= (1 - split_ratio), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization by calling the necessay functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 11\n",
    "\n",
    "# Save data to array file first (Comment next line when npy files are created to save time)\n",
    "# save_data_to_array(max_len=feature_dim_2)\n",
    "\n",
    "# Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "\n",
    "# Feature dimension\n",
    "feature_dim_1 = 20\n",
    "channel = 1\n",
    "epochs = 20\n",
    "batch_size = 100\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "\n",
    "# Reshaping to perform 2D convolution\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# def get_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(32, kernel_size=2, activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#     model.add(Conv2D(48, kernel_size=2, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#     model.add(Conv2D(120, kernel_size=2, activation='relu', data_format=\"channels_last\"))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "#     model.add(Dropout(0.1))\n",
    "\n",
    "    \n",
    "#     model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#                   optimizer=keras.optimizers.Adadelta(),\n",
    "#                   metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts a sample\n",
    "def predict(filepath, model):\n",
    "    sample = wav2mfcc(filepath)\n",
    "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    return get_labels()[0][\n",
    "            np.argmax(model.predict(sample_reshaped))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13256, 20, 11, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13256 samples, validate on 3314 samples\n",
      "Epoch 1/10\n",
      "13256/13256 [==============================] - 39s 3ms/step - loss: 1.2351 - acc: 0.5758 - val_loss: 0.6015 - val_acc: 0.7933\n",
      "Epoch 2/10\n",
      "13256/13256 [==============================] - 38s 3ms/step - loss: 0.4839 - acc: 0.8358 - val_loss: 0.4942 - val_acc: 0.8325\n",
      "Epoch 3/10\n",
      "13256/13256 [==============================] - 37s 3ms/step - loss: 0.3012 - acc: 0.8971 - val_loss: 0.4057 - val_acc: 0.8594\n",
      "Epoch 4/10\n",
      "13256/13256 [==============================] - 45s 3ms/step - loss: 0.1831 - acc: 0.9349 - val_loss: 0.4555 - val_acc: 0.8612\n",
      "Epoch 5/10\n",
      "13256/13256 [==============================] - 40s 3ms/step - loss: 0.1076 - acc: 0.9633 - val_loss: 0.3669 - val_acc: 0.8841\n",
      "Epoch 6/10\n",
      "13256/13256 [==============================] - 41s 3ms/step - loss: 0.0630 - acc: 0.9796 - val_loss: 0.3213 - val_acc: 0.9080\n",
      "Epoch 7/10\n",
      "13256/13256 [==============================] - 42s 3ms/step - loss: 0.0397 - acc: 0.9882 - val_loss: 0.3751 - val_acc: 0.9010\n",
      "Epoch 8/10\n",
      "13256/13256 [==============================] - 43s 3ms/step - loss: 0.0151 - acc: 0.9970 - val_loss: 0.3957 - val_acc: 0.9040\n",
      "Epoch 9/10\n",
      "13256/13256 [==============================] - 40s 3ms/step - loss: 0.0182 - acc: 0.9943 - val_loss: 0.5709 - val_acc: 0.8766\n",
      "Epoch 10/10\n",
      "13256/13256 [==============================] - 42s 3ms/step - loss: 0.0192 - acc: 0.9946 - val_loss: 0.4271 - val_acc: 0.9019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc84642d160>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=10, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 19, 10, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 19, 10, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 18, 9, 48)         6192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 18, 9, 48)         192       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 17, 8, 120)        23160     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 17, 8, 120)        480       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 4, 120)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               491648    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 530,671\n",
      "Trainable params: 530,271\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_built': True,\n",
      " '_collected_trainable_weights': [<tf.Variable 'conv2d_11/kernel:0' shape=(2, 2, 1, 32) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'conv2d_11/bias:0' shape=(32,) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'batch_normalization_10/gamma:0' shape=(32,) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'batch_normalization_10/beta:0' shape=(32,) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'conv2d_12/kernel:0' shape=(2, 2, 32, 48) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'conv2d_12/bias:0' shape=(48,) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'batch_normalization_11/gamma:0' shape=(48,) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'batch_normalization_11/beta:0' shape=(48,) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'conv2d_13/kernel:0' shape=(2, 2, 48, 120) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'conv2d_13/bias:0' shape=(120,) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'batch_normalization_12/gamma:0' shape=(120,) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'batch_normalization_12/beta:0' shape=(120,) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'dense_4/kernel:0' shape=(3840, 128) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'dense_4/bias:0' shape=(128,) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'dense_5/kernel:0' shape=(128, 64) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'dense_5/bias:0' shape=(64,) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'dense_6/kernel:0' shape=(64, 7) dtype=float32_ref>,\n",
      "                                  <tf.Variable 'dense_6/bias:0' shape=(7,) dtype=float32_ref>],\n",
      " '_compute_previous_mask': True,\n",
      " '_expects_training_arg': False,\n",
      " '_feed_input_names': ['conv2d_11_input'],\n",
      " '_feed_input_shapes': [(None, 20, 11, 1)],\n",
      " '_feed_inputs': [<tf.Tensor 'conv2d_11_input:0' shape=(?, 20, 11, 1) dtype=float32>],\n",
      " '_feed_loss_fns': [<function categorical_crossentropy at 0x7fc87e10f378>],\n",
      " '_feed_output_names': ['dense_6'],\n",
      " '_feed_output_shapes': [(None, 7)],\n",
      " '_feed_outputs': [<tf.Tensor 'dense_6/Softmax:0' shape=(?, 7) dtype=float32>],\n",
      " '_feed_sample_weight_modes': [None],\n",
      " '_feed_sample_weights': [<tf.Tensor 'dense_6_sample_weights:0' shape=(?,) dtype=float32>],\n",
      " '_feed_targets': [<tf.Tensor 'dense_6_target:0' shape=(?, ?) dtype=float32>],\n",
      " '_function_kwargs': {},\n",
      " '_inbound_nodes': [<keras.engine.base_layer.Node object at 0x7fc86c8422b0>],\n",
      " '_initial_weights': None,\n",
      " '_input_coordinates': [(<keras.engine.input_layer.InputLayer object at 0x7fc86c842080>,\n",
      "                         0,\n",
      "                         0)],\n",
      " '_input_layers': [<keras.engine.input_layer.InputLayer object at 0x7fc86c842080>],\n",
      " '_is_compiled': True,\n",
      " '_is_graph_network': True,\n",
      " '_layers': [<keras.engine.input_layer.InputLayer object at 0x7fc86c842080>,\n",
      "             <keras.layers.convolutional.Conv2D object at 0x7fc86c842eb8>,\n",
      "             <keras.layers.normalization.BatchNormalization object at 0x7fc86c842390>,\n",
      "             <keras.layers.convolutional.Conv2D object at 0x7fc86c884f60>,\n",
      "             <keras.layers.normalization.BatchNormalization object at 0x7fc86c857908>,\n",
      "             <keras.layers.convolutional.Conv2D object at 0x7fc86c80be80>,\n",
      "             <keras.layers.normalization.BatchNormalization object at 0x7fc86da6df98>,\n",
      "             <keras.layers.pooling.MaxPooling2D object at 0x7fc86c8343c8>,\n",
      "             <keras.layers.core.Flatten object at 0x7fc86c8d17f0>,\n",
      "             <keras.layers.core.Dense object at 0x7fc86c931198>,\n",
      "             <keras.layers.core.Dense object at 0x7fc86c9078d0>,\n",
      "             <keras.layers.core.Dense object at 0x7fc86c97ec50>],\n",
      " '_layers_by_depth': {0: [<keras.layers.core.Dense object at 0x7fc86c97ec50>],\n",
      "                      1: [<keras.layers.core.Dense object at 0x7fc86c9078d0>],\n",
      "                      2: [<keras.layers.core.Dense object at 0x7fc86c931198>],\n",
      "                      3: [<keras.layers.core.Flatten object at 0x7fc86c8d17f0>],\n",
      "                      4: [<keras.layers.pooling.MaxPooling2D object at 0x7fc86c8343c8>],\n",
      "                      5: [<keras.layers.normalization.BatchNormalization object at 0x7fc86da6df98>],\n",
      "                      6: [<keras.layers.convolutional.Conv2D object at 0x7fc86c80be80>],\n",
      "                      7: [<keras.layers.normalization.BatchNormalization object at 0x7fc86c857908>],\n",
      "                      8: [<keras.layers.convolutional.Conv2D object at 0x7fc86c884f60>],\n",
      "                      9: [<keras.layers.normalization.BatchNormalization object at 0x7fc86c842390>],\n",
      "                      10: [<keras.layers.convolutional.Conv2D object at 0x7fc86c842eb8>],\n",
      "                      11: [<keras.engine.input_layer.InputLayer object at 0x7fc86c842080>]},\n",
      " '_losses': [],\n",
      " '_network_nodes': {'batch_normalization_10_ib-0',\n",
      "                    'batch_normalization_11_ib-0',\n",
      "                    'batch_normalization_12_ib-0',\n",
      "                    'conv2d_11_ib-0',\n",
      "                    'conv2d_11_input_ib-0',\n",
      "                    'conv2d_12_ib-0',\n",
      "                    'conv2d_13_ib-0',\n",
      "                    'dense_4_ib-0',\n",
      "                    'dense_5_ib-0',\n",
      "                    'dense_6_ib-0',\n",
      "                    'flatten_2_ib-0',\n",
      "                    'max_pooling2d_9_ib-0'},\n",
      " '_nodes_by_depth': {0: [<keras.engine.base_layer.Node object at 0x7fc86c968630>],\n",
      "                     1: [<keras.engine.base_layer.Node object at 0x7fc86c973e48>],\n",
      "                     2: [<keras.engine.base_layer.Node object at 0x7fc86c9074e0>],\n",
      "                     3: [<keras.engine.base_layer.Node object at 0x7fc86c913208>],\n",
      "                     4: [<keras.engine.base_layer.Node object at 0x7fc86c8c7198>],\n",
      "                     5: [<keras.engine.base_layer.Node object at 0x7fc86c8c7be0>],\n",
      "                     6: [<keras.engine.base_layer.Node object at 0x7fc86c8db160>],\n",
      "                     7: [<keras.engine.base_layer.Node object at 0x7fc86c816710>],\n",
      "                     8: [<keras.engine.base_layer.Node object at 0x7fc86c80b438>],\n",
      "                     9: [<keras.engine.base_layer.Node object at 0x7fc86c84dda0>],\n",
      "                     10: [<keras.engine.base_layer.Node object at 0x7fc86c8b8b38>],\n",
      "                     11: [<keras.engine.base_layer.Node object at 0x7fc86c842160>]},\n",
      " '_outbound_nodes': [],\n",
      " '_output_coordinates': [(<keras.layers.core.Dense object at 0x7fc86c97ec50>,\n",
      "                          0,\n",
      "                          0)],\n",
      " '_output_layers': [<keras.layers.core.Dense object at 0x7fc86c97ec50>],\n",
      " '_output_mask_cache': {'140498790786104_94335365704496': None},\n",
      " '_output_shape_cache': {},\n",
      " '_output_tensor_cache': {},\n",
      " '_per_input_losses': {},\n",
      " '_per_input_updates': {},\n",
      " '_updates': [],\n",
      " '_uses_inputs_arg': True,\n",
      " 'history': <keras.callbacks.History object at 0x7fc86c842d68>,\n",
      " 'input_names': ['conv2d_11_input'],\n",
      " 'inputs': [<tf.Tensor 'conv2d_11_input:0' shape=(?, 20, 11, 1) dtype=float32>],\n",
      " 'loss': <function categorical_crossentropy at 0x7fc87e10f378>,\n",
      " 'loss_functions': [<function categorical_crossentropy at 0x7fc87e10f378>],\n",
      " 'loss_weights': None,\n",
      " 'metrics': ['accuracy'],\n",
      " 'metrics_names': ['loss', 'acc'],\n",
      " 'metrics_tensors': [<tf.Tensor 'metrics_1/acc/Mean:0' shape=() dtype=float32>],\n",
      " 'metrics_updates': [],\n",
      " 'name': 'sequential_5',\n",
      " 'optimizer': <keras.optimizers.Adadelta object at 0x7fc86c9731d0>,\n",
      " 'output_names': ['dense_6'],\n",
      " 'outputs': [<tf.Tensor 'dense_6/Softmax:0' shape=(?, 7) dtype=float32>],\n",
      " 'predict_function': None,\n",
      " 'sample_weight_mode': None,\n",
      " 'sample_weight_modes': [None],\n",
      " 'sample_weights': [<tf.Tensor 'dense_6_sample_weights:0' shape=(?,) dtype=float32>],\n",
      " 'stateful_metric_functions': [],\n",
      " 'stateful_metric_names': [],\n",
      " 'stop_training': False,\n",
      " 'supports_masking': False,\n",
      " 'targets': [<tf.Tensor 'dense_6_target:0' shape=(?, ?) dtype=float32>],\n",
      " 'test_function': <keras.backend.tensorflow_backend.Function object at 0x7fc86c973828>,\n",
      " 'total_loss': <tf.Tensor 'loss_1/mul:0' shape=() dtype=float32>,\n",
      " 'train_function': <keras.backend.tensorflow_backend.Function object at 0x7fc86c9683c8>,\n",
      " 'trainable': True,\n",
      " 'weighted_metrics': None}\n"
     ]
    }
   ],
   "source": [
    "# A nice method to check all the attributes of an object\n",
    "from pprint import pprint\n",
    "pprint(vars(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left\n"
     ]
    }
   ],
   "source": [
    "print(predict('./eng_data/left/1cc80e39_nohash_0.wav', model=model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence(filepath, model):\n",
    "    sample = wav2mfcc(filepath)\n",
    "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    u = model.predict(sample_reshaped)\n",
    "#     print(u)\n",
    "    return u, get_labels()[0][\n",
    "            np.argmax(model.predict(sample_reshaped))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = get_labels()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down      3.5824613e-16\n",
      "go      3.0647503e-12\n",
      "left      1.0\n",
      "on      1.160079e-13\n",
      "right      4.758897e-09\n",
      "up      3.4712777e-10\n",
      "yes      1.6291062e-11\n",
      "left\n"
     ]
    }
   ],
   "source": [
    "confs, word = confidence('./eng_data/left/1cc80e39_nohash_0.wav', model=model)\n",
    "for lab,conf in zip(labs,confs[0]):\n",
    "    print(lab , \"    \" ,conf)\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence(new_sample, model):\n",
    "\n",
    "    new_sample = new_sample.reshape(-1)\n",
    "    # print(\"Ye: \" + str(new_sample.shape))\n",
    "    sample = array2mfcc(new_sample)\n",
    "    sample_reshaped = sample.reshape(1,20,11,1)\n",
    "    return model.predict(sample_reshaped)\n",
    "\n",
    "\n",
    "def get_conf(inp, model):\n",
    "    labs = get_labels()[0]\n",
    "    inp = np.array(inp)\n",
    "    confs = confidence(inp, model=model)\n",
    "#     print(\"zzz\")\n",
    "#     print(confs[0])\n",
    "#     print(labs)\n",
    "    for lab,conf in zip(labs,confs[0]):\n",
    "        print(lab , \"    \" ,conf)\n",
    "    # print(word)\n",
    "    \n",
    "def get_conf2(sample, model):\n",
    "    for a,b in zip(get_labels()[0], model.predict(sample)[0]):\n",
    "        print(a, \"     \", b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in model.predict(sample_reshaped)[0]:\n",
    "#     print(i)\n",
    "# model.predict(sample_reshaped)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model in realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the recorded array to mfcc\n",
    "Instead of recording speech into a file and reading from it to create an array, this function would directly convert the recorded array into mfcc coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array2mfcc(wave, max_len=11):\n",
    "    sr = 16000\n",
    "    wave = wave[::3]\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
    "\n",
    "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
    "    if (max_len > mfcc.shape[1]):\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    # Else cutoff the remaining parts\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    \n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['down', 'go', 'left', 'on', 'right', 'up', 'yes']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For reference: These are the words trained to the classifier \n",
    "get_labels()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording...\n",
    "Please speak after executing the next cell.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 1  # seconds\n",
    "fs = 16000\n",
    "new_sample = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
    "time.sleep(duration)\n",
    "sd.play(new_sample, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "down       0.00019802894\n",
      "go       0.91213584\n",
      "left       7.179345e-05\n",
      "on       0.0728288\n",
      "right       0.014749701\n",
      "up       1.5815662e-05\n",
      "yes       1.6174128e-07\n"
     ]
    }
   ],
   "source": [
    "new_sample = new_sample.reshape(-1)\n",
    "sample = array2mfcc(new_sample)\n",
    "sample_reshaped = sample.reshape(1,20,11,1)\n",
    "\n",
    "print(get_labels()[0][np.argmax(model.predict(sample_reshaped))])\n",
    "get_conf2(sample_reshaped, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..stop.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model73.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model73.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('model1.json', 'r')\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"model1.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
