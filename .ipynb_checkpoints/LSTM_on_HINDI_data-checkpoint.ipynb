{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "import librosa\n",
    "from python_speech_features import mfcc as mf\n",
    "import scipy.io.wavfile as wav\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"hindi_dataset_mp3\"\n",
    "path_wav = \"hindi_dataset_wav\"\n",
    "people = os.listdir(path)\n",
    "words = [[] for i in range(27)]\n",
    "\n",
    "for i,name in enumerate(people):\n",
    "    print(i,name)\n",
    "    folderpath = path + \"/\" + name + \"/\"\n",
    "    folderpath_wav = path_wav + \"/\" + name + \"/\"\n",
    "    for j in range(1,27):\n",
    "        tmp = os.listdir(folderpath+str(j))\n",
    "        tmp_wav = folderpath_wav+str(j)\n",
    "        filepaths = [folderpath+str(j)+\"/\"+k for k in tmp]\n",
    "        #print(filepaths)\n",
    "        z=0\n",
    "        for filepath in filepaths:\n",
    "            z = z+1\n",
    "            src = filepath\n",
    "            dst = tmp_wav+\"/\"+str(z)+\".wav\"\n",
    "            sound = AudioSegment.from_mp3(src)\n",
    "            sound.export(dst, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"hindi_dataset_mp3\"\n",
    "path_wav = \"hindi_dataset_wav_2\"\n",
    "people = os.listdir(path)\n",
    "words = [[] for i in range(27)]\n",
    "\n",
    "for i,name in enumerate(people):\n",
    "    print(i,name)\n",
    "    folderpath = path + \"/\" + name + \"/\"\n",
    "    for j in range(1,27):\n",
    "        tmp = os.listdir(folderpath+str(j))\n",
    "        filepaths = [folderpath+str(j)+\"/\"+k for k in tmp]\n",
    "        #print(filepaths)\n",
    "        z=0\n",
    "        for filepath in filepaths:\n",
    "            z = z+1\n",
    "            src = filepath\n",
    "            dst = path_wav+\"/\"+str(j)+\"/\"+name+str(z)+\".wav\"\n",
    "            sound = AudioSegment.from_mp3(src)\n",
    "            sound.export(dst, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2mfcc(file_path, max_pad_len=450):\n",
    "    #wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "    sr, wave = wav.read(file_path)\n",
    "    #wave = wave[::3]\n",
    "    #print(\" AA \" + str(wave.shape))\n",
    "    mfcc = mf(wave,sr,nfft=2048)\n",
    "    #mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
    "    #print(\" BB \" + str(mfcc.shape))\n",
    "    mfcc = mfcc.T\n",
    "    #print(\" CC \" + str(mfcc.shape))\n",
    "    pad_width = max_pad_len-mfcc.shape[1]\n",
    "    if(pad_width < 0):\n",
    "        print(\" AA \"+ str(pad_width))\n",
    "        print(file_path)\n",
    "        pad_width = 50\n",
    "    mfcc = np.pad(mfcc, pad_width=((0,0), (0,pad_width)),mode='constant')\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './hindi_dataset_wav_2/'\n",
    "\n",
    "def get_labels(path = DATA_PATH):\n",
    "    labels = os.listdir(path)\n",
    "    #print(labels)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, to_categorical(label_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_array(path=DATA_PATH, max_pad_len=450):\n",
    "    labels, _, _ = get_labels(path)\n",
    "    \n",
    "    for i,label in enumerate(labels):\n",
    "        mfcc_vectors = []\n",
    "        wavfiles = [path+label+'/'+wavfile for wavfile in os.listdir(path+'/'+label)]\n",
    "        for wavfile in wavfiles:\n",
    "            mfcc = wav2mfcc(wavfile, max_pad_len=max_pad_len)\n",
    "            mfcc_vectors.append(mfcc)\n",
    "        print(label)\n",
    "        np.save(label+'.npy', mfcc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(split_ratio=0.6, random_state=42):\n",
    "    labels, indices, _ = get_labels(DATA_PATH)\n",
    "    print(labels,indices)\n",
    "    X = np.load(labels[0]+'.npy')\n",
    "    print(X.shape)\n",
    "    y = np.zeros(X.shape[0])\n",
    "    \n",
    "    for i, label in enumerate(labels[1:]):\n",
    "        x = np.load(label+'.npy')\n",
    "        X = np.vstack((X,x))\n",
    "        y = np.append(y, np.full(x.shape[0], fill_value=(i+1)))\n",
    "        \n",
    "    assert X.shape[0] == len(y)\n",
    "    \n",
    "    return train_test_split(X,y,test_size=(1-split_ratio), random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "11\n",
      "5\n",
      "20\n",
      "16\n",
      "3\n",
      "23\n",
      "8\n",
      "1\n",
      "15\n",
      "21\n",
      "2\n",
      "25\n",
      "14\n",
      "7\n",
      "13\n",
      "22\n",
      "4\n",
      "10\n",
      "9\n",
      "24\n",
      "17\n",
      "12\n",
      "26\n",
      "6\n",
      "19\n",
      "['18', '11', '5', '20', '16', '3', '23', '8', '1', '15', '21', '2', '25', '14', '7', '13', '22', '4', '10', '9', '24', '17', '12', '26', '6', '19'] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n",
      "(102, 13, 450)\n",
      "(1628, 13, 450)\n"
     ]
    }
   ],
   "source": [
    "save_data_to_array()\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1628, 13, 450)\n",
      "(1086, 13, 450)\n",
      "(1628,)\n",
      "(1086,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25.]\n",
      "(1628, 26)\n",
      "(1628,)\n"
     ]
    }
   ],
   "source": [
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "print(np.unique(y_train))\n",
    "print(y_train_hot.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1628/1628 [==============================] - 12s 7ms/step - loss: 0.0370\n",
      "Epoch 2/50\n",
      "1628/1628 [==============================] - 4s 2ms/step - loss: 0.0367\n",
      "Epoch 3/50\n",
      "1628/1628 [==============================] - 4s 2ms/step - loss: 0.0359\n",
      "Epoch 4/50\n",
      "1628/1628 [==============================] - 5s 3ms/step - loss: 0.0350\n",
      "Epoch 5/50\n",
      "1628/1628 [==============================] - 5s 3ms/step - loss: 0.0337\n",
      "Epoch 6/50\n",
      "1628/1628 [==============================] - 4s 2ms/step - loss: 0.0326\n",
      "Epoch 7/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0327\n",
      "Epoch 8/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0314\n",
      "Epoch 9/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0308\n",
      "Epoch 10/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0297\n",
      "Epoch 11/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0288\n",
      "Epoch 12/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0295\n",
      "Epoch 13/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0288\n",
      "Epoch 14/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0268\n",
      "Epoch 15/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0259\n",
      "Epoch 16/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0250\n",
      "Epoch 17/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0248\n",
      "Epoch 18/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0243\n",
      "Epoch 19/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0242\n",
      "Epoch 20/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0238\n",
      "Epoch 21/50\n",
      "1628/1628 [==============================] - 4s 2ms/step - loss: 0.0227\n",
      "Epoch 22/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0220\n",
      "Epoch 23/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0213\n",
      "Epoch 24/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0212\n",
      "Epoch 25/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0195\n",
      "Epoch 26/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0200\n",
      "Epoch 27/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0193\n",
      "Epoch 28/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0185\n",
      "Epoch 29/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0176\n",
      "Epoch 30/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0174\n",
      "Epoch 31/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0170\n",
      "Epoch 32/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0168\n",
      "Epoch 33/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0172\n",
      "Epoch 34/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0156\n",
      "Epoch 35/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0154\n",
      "Epoch 36/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0158\n",
      "Epoch 37/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0151\n",
      "Epoch 38/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0133\n",
      "Epoch 39/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0132\n",
      "Epoch 40/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0129\n",
      "Epoch 41/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0124\n",
      "Epoch 42/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0118\n",
      "Epoch 43/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0116\n",
      "Epoch 44/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0112\n",
      "Epoch 45/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0122\n",
      "Epoch 46/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0118\n",
      "Epoch 47/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0114\n",
      "Epoch 48/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0110\n",
      "Epoch 49/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0109\n",
      "Epoch 50/50\n",
      "1628/1628 [==============================] - 3s 2ms/step - loss: 0.0102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f956b79af60>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 100))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(26, activation='softmax'))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train_hot, epochs = 50, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "sample = wav2mfcc('./hindi_dataset_wav_2/1/Agam2.wav')\n",
    "sample_reshaped = sample.reshape(1,13,450)\n",
    "print(get_labels()[0][np.argmax(regressor.predict(sample_reshaped))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "sample = wav2mfcc('./hindi_dataset_wav_2/1/Agam1.wav')\n",
    "sample_reshaped = sample.reshape(1,13,450)\n",
    "print(get_labels()[0][np.argmax(regressor.predict(sample_reshaped))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "sample = wav2mfcc('./hindi_dataset_wav_2/1/Agam9.wav')\n",
    "sample_reshaped = sample.reshape(1,13,450)\n",
    "print(get_labels()[0][np.argmax(regressor.predict(sample_reshaped))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "sample = wav2mfcc('./hindi_dataset_wav_2/1/Agam3.wav')\n",
    "sample_reshaped = sample.reshape(1,13,450)\n",
    "print(get_labels()[0][np.argmax(regressor.predict(sample_reshaped))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "sample = wav2mfcc('./hindi_dataset_wav_2/1/Agam4.wav')\n",
    "sample_reshaped = sample.reshape(1,13,450)\n",
    "print(get_labels()[0][np.argmax(regressor.predict(sample_reshaped))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "sample = wav2mfcc('./hindi_dataset_wav_2/1/Agam5.wav')\n",
    "sample_reshaped = sample.reshape(1,13,450)\n",
    "print(get_labels()[0][np.argmax(regressor.predict(sample_reshaped))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "sample = wav2mfcc('./hindi_dataset_wav_2/1/Agam6.wav')\n",
    "sample_reshaped = sample.reshape(1,13,450)\n",
    "print(get_labels()[0][np.argmax(regressor.predict(sample_reshaped))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "sample = wav2mfcc('./hindi_dataset_wav_2/1/Agam7.wav')\n",
    "sample_reshaped = sample.reshape(1,13,450)\n",
    "print(get_labels()[0][np.argmax(regressor.predict(sample_reshaped))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "sample = wav2mfcc('./hindi_dataset_wav_2/1/Agam8.wav')\n",
    "sample_reshaped = sample.reshape(1,13,450)\n",
    "print(get_labels()[0][np.argmax(regressor.predict(sample_reshaped))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "sample = wav2mfcc('./hindi_dataset_wav_2/1/Ruchin8.wav')\n",
    "sample_reshaped = sample.reshape(1,13,450)\n",
    "print(get_labels()[0][np.argmax(regressor.predict(sample_reshaped))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
